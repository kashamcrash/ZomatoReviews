{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model to predict the rating in a review based on the content of the text review, identify any mismatch\n",
    "# Credentials: kasham1991@gmail.com / karan sharma\n",
    "\n",
    "# Agenda\n",
    "# 1. Perform specific data cleanup, \n",
    "# 2. Build a rating prediction model using the Random Forest technique and NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Their service is worst, pricing in menu is dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>really appreciate their quality and timing . I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Went there on a Friday night, the place was su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A very decent place serving good food.\\r\\nOrde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>One of the BEST places for steaks in the city....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                        review_text\n",
       "0     1.0  Their service is worst, pricing in menu is dif...\n",
       "1     5.0  really appreciate their quality and timing . I...\n",
       "2     4.0  Went there on a Friday night, the place was su...\n",
       "3     4.0  A very decent place serving good food.\\r\\nOrde...\n",
       "4     5.0  One of the BEST places for steaks in the city...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "zomato = pd.read_csv('C://Datasets//ZomatoReviews.csv')\n",
    "zomato.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27762.000000</td>\n",
       "      <td>27748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.665784</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.284573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rating review_text\n",
       "count   27762.000000       27748\n",
       "unique           NaN       10548\n",
       "top              NaN        good\n",
       "freq             NaN         278\n",
       "mean        3.665784         NaN\n",
       "std         1.284573         NaN\n",
       "min         1.000000         NaN\n",
       "25%         3.000000         NaN\n",
       "50%         4.000000         NaN\n",
       "75%         5.000000         NaN\n",
       "max         5.000000         NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics of the dataset\n",
    "# Multiple records in review_text are missing\n",
    "zomato.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14 rows are missing the review text - need to get rid of these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the missing values\n",
    "zomato1 = zomato[~zomato.review_text.isnull()].copy()\n",
    "zomato1.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27762, 2), (27748, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape\n",
    "zomato.shape, zomato1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27748"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to list\n",
    "zomato_list = zomato1.review_text.values\n",
    "len(zomato_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text: Step-by-Step\n",
    "\n",
    "# 1. Normalizing\n",
    "# 2. Removing extra line breaks from the text\n",
    "# 3. Removing stop words\n",
    "# 4. Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went there on a friday night, the place was surprisingly empty. interesting menu which is almost fully made of dosas. i had bullseye dosa and cheese masala dosa. the bullseye dosa was really good, with the egg perfectly cooked to a half boiled state. the masala in the cheese masala was good, but the cheese was a bit too chewy for my liking. the chutney was good, the sambar was average. the dishes are reasonably priced.',\n",
       " 'a very decent place serving good food.\\r\\nordered chilli fish, chicken & pork sizzler.\\r\\neverything tasted good but pork could have been slightly better cooked.\\r\\ntried 2 beverages, both were very sweet.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing to lower case\n",
    "lower = [txt.lower() for txt in zomato_list]\n",
    "lower[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went there on a friday night, the place was surprisingly empty. interesting menu which is almost fully made of dosas. i had bullseye dosa and cheese masala dosa. the bullseye dosa was really good, with the egg perfectly cooked to a half boiled state. the masala in the cheese masala was good, but the cheese was a bit too chewy for my liking. the chutney was good, the sambar was average. the dishes are reasonably priced.',\n",
       " 'a very decent place serving good food. ordered chilli fish, chicken & pork sizzler. everything tasted good but pork could have been slightly better cooked. tried 2 beverages, both were very sweet.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing extra line breaks\n",
    "line_break = [\" \".join(txt.split()) for txt in lower]\n",
    "line_break[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['their', 'service', 'is', 'worst', ',', 'pricing', 'in', 'menu', 'is', 'different', 'from', 'bill', '.', 'they', 'can', 'give', 'you', 'a', 'bill', 'with', 'increased', 'pricing', '.', 'even', 'for', 'serving', 'water', ',', 'menu', ',', 'order', 'you', 'need', 'to', 'call', 'them', '3-4', 'times', 'even', 'on', 'a', 'non', 'busy', 'day', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(line_break[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "their service is worst, pricing in menu is different from bill. they can give you a bill with increased pricing. even for serving water,menu, order you need to call them 3-4 times even on a non busy day.\n"
     ]
    }
   ],
   "source": [
    "zomato_tokens = [word_tokenize(sent) for sent in line_break]\n",
    "print(line_break[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words and punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stop_nltk = stopwords.words(\"english\")\n",
    "stop_punct = list(punctuation)\n",
    "print(stop_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing no, not, don, won from stop words\n",
    "# These words are important for rating \n",
    "stop_nltk.remove(\"no\")\n",
    "stop_nltk.remove(\"not\")\n",
    "stop_nltk.remove(\"don\")\n",
    "stop_nltk.remove(\"won\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the same\n",
    "\"no\" in stop_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_final = stop_nltk + stop_punct + [\"...\", \"``\",\"''\", \"====\", \"must\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['really',\n",
       " 'appreciate',\n",
       " 'quality',\n",
       " 'timing',\n",
       " 'tried',\n",
       " 'thattil',\n",
       " 'kutti',\n",
       " 'dosa',\n",
       " \"'ve\",\n",
       " 'addicted',\n",
       " 'dosa',\n",
       " 'really',\n",
       " 'chutney',\n",
       " 'really',\n",
       " 'good',\n",
       " 'money',\n",
       " 'worth',\n",
       " 'much',\n",
       " 'better',\n",
       " 'thattukada',\n",
       " 'try']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function for the steps mentioned above\n",
    "def delete(sent):\n",
    "    return [term for term in sent if term not in stop_final]\n",
    "\n",
    "delete(zomato_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final clean list\n",
    "zomato_clean = [delete(sent) for sent in zomato_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['service worst pricing menu different bill give bill increased pricing even serving water menu order need call 3-4 times even non busy day',\n",
       " \"really appreciate quality timing tried thattil kutti dosa 've addicted dosa really chutney really good money worth much better thattukada try\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean = [\" \".join(sent) for sent in zomato_clean]\n",
    "final_clean[:2]\n",
    "# len(final_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset by 70/30\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = final_clean\n",
    "y = zomato1.rating\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19423, 5000), (8325, 5000))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating TfIdf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vector = TfidfVectorizer(max_features = 5000)\n",
    "# len(x_train), len(x_test)\n",
    "\n",
    "x_train_bow = vector.fit_transform(x_train)\n",
    "x_test_bow = vector.transform(x_test)\n",
    "x_train_bow.shape, x_test_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building with RF and GBR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestRegressor(random_state = 42, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit(x_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26487948954941426"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the prediction\n",
    "# RSME score\n",
    "y_train_preds = model1.predict(x_train_bow)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, y_train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the number of trees\n",
    "model2 = RandomForestRegressor(random_state = 42, n_estimators = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=20, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model2.fit(x_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24979450237391482"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RSME post 20 tress as estimators\n",
    "y_train_preds = model2.predict(x_train_bow)\n",
    "mean_squared_error(y_train, y_train_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best hyper-parameters for the SVM classifier\n",
    "# Hyperparameter tuning and GridSearch\n",
    "# max_features – ‘auto’, ‘sqrt’, ‘log2’\n",
    "# max_depth – 10, 15, 20, 25\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestRegressor(random_state = 42, n_estimators = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_features': [500, \"sqrt\", \"log2\", \"auto\"],\n",
    "    'max_depth': [10, 15, 20, 25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model with stratified 5 fold cross-validation scheme\n",
    "grid_search = GridSearchCV(estimator = model3, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 1, scoring = \"neg_mean_squared_error\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestRegressor(n_estimators=30, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 15, 20, 25],\n",
       "                         'max_features': [500, 'sqrt', 'log2', 'auto']},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_depth', 'param_max_features', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=25, max_features=500, n_estimators=30,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set with RSME\n",
    "# The score are higher than before\n",
    "y_train_pred = grid_search.best_estimator_.predict(x_train_bow)\n",
    "y_test_pred = grid_search.best_estimator_.predict(x_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993171473290868"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6851577785321694"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_test_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>tum se na ho paye gaa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.622235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13512</th>\n",
       "      <td>went place cousin.the onion rings wat get one ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.502563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17968</th>\n",
       "      <td>amazing place even better food one places bang...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.525573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>truffles known burgers italian food find alway...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.117811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202</th>\n",
       "      <td>like home food liked gatte curry would definit...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.879688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372</th>\n",
       "      <td>one restaurants open late hours koramangala ar...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.117060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>weekend evening one happening places bangalore...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.284457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17028</th>\n",
       "      <td>one worst restaurant ever seen ordered paneer ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22272</th>\n",
       "      <td>yesterday ordered food dinner outlet place act...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.920376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21434</th>\n",
       "      <td>place complements name service amazing fast fo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.892148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8325 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  rating_pred\n",
       "2932                               tum se na ho paye gaa     1.0     3.622235\n",
       "13512  went place cousin.the onion rings wat get one ...     5.0     4.502563\n",
       "17968  amazing place even better food one places bang...     5.0     4.525573\n",
       "3496   truffles known burgers italian food find alway...     4.0     4.117811\n",
       "17202  like home food liked gatte curry would definit...     4.0     3.879688\n",
       "...                                                  ...     ...          ...\n",
       "22372  one restaurants open late hours koramangala ar...     2.0     2.117060\n",
       "3525   weekend evening one happening places bangalore...     4.0     4.284457\n",
       "17028  one worst restaurant ever seen ordered paneer ...     1.0     1.002448\n",
       "22272  yesterday ordered food dinner outlet place act...     4.0     3.920376\n",
       "21434  place complements name service amazing fast fo...     3.0     3.892148\n",
       "\n",
       "[8325 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for any mismatches\n",
    "# Creating a crosstab for the same\n",
    "# Calculating the difference\n",
    "difference = pd.DataFrame({'review':x_test, 'rating':y_test, 'rating_pred':y_test_pred})\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>not good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.665161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25813</th>\n",
       "      <td>ordered almost veg pizzas economic really good...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.872747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>paneer tikka veg seekh kebab order made place ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.646035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25821</th>\n",
       "      <td>ordered almost veg pizzas economic really good...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.872747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>not good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.665161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>not good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.665161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>not good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.665161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15201</th>\n",
       "      <td>sauce not included</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.762460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7166</th>\n",
       "      <td>first experience worst ordered egg biriyani zo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.738853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25825</th>\n",
       "      <td>ordered almost veg pizzas economic really good...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.872747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>still di n't receive order</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.825877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>'ve eating lunch every day unlike places food ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.385941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>no leg piece ....</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.783314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25634</th>\n",
       "      <td>vegeterian food excellent except sweet corn so...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.885276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20194</th>\n",
       "      <td>order pizza place late night .. omg surprise f...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.732087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25809</th>\n",
       "      <td>ordered almost veg pizzas economic really good...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.872747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25817</th>\n",
       "      <td>ordered almost veg pizzas economic really good...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.872747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  rating_pred\n",
       "4766                                            not good     5.0     1.665161\n",
       "25813  ordered almost veg pizzas economic really good...     5.0     1.872747\n",
       "20400  paneer tikka veg seekh kebab order made place ...     5.0     2.646035\n",
       "25821  ordered almost veg pizzas economic really good...     5.0     1.872747\n",
       "4771                                            not good     5.0     1.665161\n",
       "4776                                            not good     5.0     1.665161\n",
       "4761                                            not good     5.0     1.665161\n",
       "15201                                 sauce not included     4.0     1.762460\n",
       "7166   first experience worst ordered egg biriyani zo...     4.0     1.738853\n",
       "25825  ordered almost veg pizzas economic really good...     5.0     1.872747\n",
       "6653                          still di n't receive order     5.0     2.825877\n",
       "5186   've eating lunch every day unlike places food ...     4.5     2.385941\n",
       "2843                                   no leg piece ....     4.0     1.783314\n",
       "25634  vegeterian food excellent except sweet corn so...     4.0     1.885276\n",
       "20194  order pizza place late night .. omg surprise f...     5.0     2.732087\n",
       "25809  ordered almost veg pizzas economic really good...     5.0     1.872747\n",
       "25817  ordered almost veg pizzas economic really good...     5.0     1.872747"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = difference[(difference.rating - difference.rating_pred)>=2]\n",
    "# a.shape\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank You :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
